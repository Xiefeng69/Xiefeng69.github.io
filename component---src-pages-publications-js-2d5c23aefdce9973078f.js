"use strict";(self.webpackChunkgatsby_starter_default=self.webpackChunkgatsby_starter_default||[]).push([[937],{1046:function(e,t,n){n.d(t,{w_:function(){return c}});var a=n(7294),i={color:void 0,size:void 0,className:void 0,style:void 0,attr:void 0},o=a.createContext&&a.createContext(i),r=function(){return r=Object.assign||function(e){for(var t,n=1,a=arguments.length;n<a;n++)for(var i in t=arguments[n])Object.prototype.hasOwnProperty.call(t,i)&&(e[i]=t[i]);return e},r.apply(this,arguments)},s=function(e,t){var n={};for(var a in e)Object.prototype.hasOwnProperty.call(e,a)&&t.indexOf(a)<0&&(n[a]=e[a]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var i=0;for(a=Object.getOwnPropertySymbols(e);i<a.length;i++)t.indexOf(a[i])<0&&Object.prototype.propertyIsEnumerable.call(e,a[i])&&(n[a[i]]=e[a[i]])}return n};function l(e){return e&&e.map((function(e,t){return a.createElement(e.tag,r({key:t},e.attr),l(e.child))}))}function c(e){return function(t){return a.createElement(d,r({attr:r({},e.attr)},t),l(e.child))}}function d(e){var t=function(t){var n,i=e.attr,o=e.size,l=e.title,c=s(e,["attr","size","title"]),d=o||t.size||"1em";return t.className&&(n=t.className),e.className&&(n=(n?n+" ":"")+e.className),a.createElement("svg",r({stroke:"currentColor",fill:"currentColor",strokeWidth:"0"},t.attr,i,c,{className:n,style:r(r({color:e.color||t.color},t.style),e.style),height:d,width:d,xmlns:"http://www.w3.org/2000/svg"}),l&&a.createElement("title",null,l),e.children)};return void 0!==o?a.createElement(o.Consumer,null,(function(e){return t(e)})):t(i)}},1145:function(e,t,n){n.r(t);var a=n(3433),i=n(7294),o=(n(6411),n(6558)),r=n(2810),s=n(2988),l=n(1279),c=n(6473),d=function(e){return void 0!==e&&""!=e};t.default=function(){for(var e="all",t=[],n=0;n<(0,s.Z)(e).length;n++)t.push(!1);var p=(0,i.useState)(t),h=p[0],u=p[1];return i.createElement("div",null,i.createElement("div",{className:"main-center"},i.createElement(c.Z,null,i.createElement("div",{className:"navigator"},i.createElement("a",{href:"/",style:{color:"black"}},"homepage")," \\ publications")),i.createElement("p",{style:{fontWeight:"bold",fontSize:"1.6rem",marginBottom:"10px"}},"Publications"),i.createElement("div",{className:"tldr_info"},i.createElement(l.kA6,null),i.createElement("div",{style:{width:"5px"}}),i.createElement("span",null,"* indicates equal contribution")),0!=(0,s.Z)(e).length?(0,s.Z)(e).map((function(e,t){return i.createElement("div",{className:"pub_container",key:t,attr:e,style:{marginBottom:"14px"}},i.createElement("div",{className:"title"},e.title),i.createElement("p",{style:{color:"black",fontSize:".9rem"},dangerouslySetInnerHTML:{__html:e.author}}),i.createElement("p",{style:{color:"#494e52",fontStyle:"italic",fontSize:".9rem"}},e.venues," ",d(e.abbr)?i.createElement("span",{style:{fontWeight:"bold"}},"(",e.abbr,")"):null),i.createElement("div",{style:{marginTop:".2rem"}}),d(e.pdf)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{href:e.pdf,target:"_blank"},"PDF")):null,d(e.code)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{href:e.code,target:"_blank"},"Code")):null,d(e.poster)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{href:e.poster,target:"_blank"},"Poster")):null,d(e.slide)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{href:e.slide,target:"_blank"},"Slide")):null,d(e.page)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{href:e.page},"Page")):null,d(e.tldr)?i.createElement("span",{className:"linkbutton"},i.createElement("a",{onClick:function(){!function(e,t,n){console.log(t[e]);var i=(0,a.Z)(t);1==i[e]?i[e]=!1:i[e]=!0,n(i),console.log(t[e])}(t,h,u)}},"Abstract")):null,h[t]?i.createElement("div",{className:"tldr_card"},e.tldr):null)})):i.createElement("div",null,"Coming Soooooooon!")),i.createElement(o.Z,{visibilityHeight:150}),i.createElement(r.Z,null))}},2988:function(e,t){t.Z=function(e){var t=[{author:"<span style='font-weight:bold'}>Feng Xie</span>, Xin Song, Xiang Zeng, Xuechen Zhao, Lei Tian, Bin Zhou, Yusong Tan.",title:"MixTEA: Semi-supervised Entity Alignment with Mixture Teaching",venues:"The 2023 Conference on Empirical Methods in Natural Language Processing",abbr:"EMNLP 2023",ccf:"CCF-B",type:"KG",pdf:"https://aclanthology.org/2023.findings-emnlp.63/",code:"https://github.com/Xiefeng69/MixTEA",page:"",slide:"",comment:"",tldr:"Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method."},{author:"<span style='font-weight:bold'}>Feng Xie</span>, Xiang Zeng, Bin Zhou and Yusong Tan.",title:"Improving Knowledge Graph Entity Alignment with Graph Augmentation",venues:"The 27th Pacific-Asia Conference on Knowledge Discovery and Data Mining",abbr:"PAKDD 2023",ccf:"CCF-C",type:"KG",pdf:"https://link.springer.com/chapter/10.1007/978-3-031-33377-4_1",code:"https://github.com/Xiefeng69/GAEA",page:"",slide:"/static/GAEA_presentation.pdf",comment:"",tldr:"Entity alignment (EA) which links equivalent entities across different knowledge graphs (KGs) plays a crucial role in knowledge fusion. In recent years, graph neural networks (GNNs) have been successfully applied in many embedding-based EA methods. However, existing GNN-based methods either suffer from the structural heterogeneity issue that especially appears in the real KG distributions or ignore the heterogeneous representation learning for unseen (unlabeled) entities, which would lead the model to overfit on few alignment seeds (i.e., training data) and thus cause unsatisfactory alignment performance. To enhance the EA ability, we propose GAEA, a novel EA approach based on graph augmentation. In this model, we design a simple Entity-Relation (ER) Encoder to generate latent representations for entities via jointly modeling comprehensive structural information and rich relation semantics. Moreover, we use graph augmentation to create two graph views for margin-based alignment learning and contrastive entity representation learning, thus mitigating structural heterogeneity and further improving the model's alignment performance. Extensive experiments conducted on benchmark datasets demonstrate the effectiveness of our method."},{author:"<span style='font-weight:bold'}>Feng Xie</span>*, Zhong Zhang*, Xuechen Zhao, Haiyang Wang, Jiaying Zou, Lei Tian, Bin Zhou and Yusong Tan.",title:"Adversarial Learning-based Stance Classifier for COVID-19-related Health Policies",venues:"The 28th International Conference on Database Systems for Advanced Applications",abbr:"DASFAA 2023",ccf:"CCF-B",type:"NLP",pdf:"https://link.springer.com/chapter/10.1007/978-3-031-30678-5_18",poster:"/static/dasfaa-poster.pdf",code:"https://github.com/Xiefeng69/stance-detection-for-covid19-related-health-policies",page:"",slide:"",comment:"",tldr:"The ongoing COVID-19 pandemic has caused immeasurable losses for people worldwide. To contain the spread of the virus and further alleviate the crisis, various health policies (e.g., stay-at-home orders) have been issued which spark heated discussions as users turn to share their attitudes on social media. In this paper, we consider a more realistic scenario on stance detection (i.e., cross-target and zero-shot settings) for the pandemic and propose an adversarial learning-based stance classifier to automatically identify the public's attitudes toward COVID-19-related health policies. Specifically, we adopt adversarial learning that allows the model to train on a large amount of labeled data and capture transferable knowledge from source topics, so as to enable generalize to the emerging health policies with sparse labeled data. To further enhance the model's deeper understanding, we incorporate policy descriptions as external knowledge into the model. Meanwhile, a GeoEncoder is designed which encourages the model to capture unobserved background factors specified by each region and then represent them as non-text information. We evaluate the performance of a broad range of baselines on the stance detection task for COVID-19-related health policies, and experimental results show that our proposed method achieves state-of-the-art performance in both cross-target and zero-shot settings."},{author:"Xuechen Zhao, Jiaying Zou, Zhong Zhang, <span style='font-weight:bold'}>Feng Xie</span>, Bin Zhou and Lei Tian.",title:"Feature Enhanced Zero-Shot Stance Detection via Contrastive Learning",venues:"SIAM International Conference on Data Mining",abbr:"SDM 2023",ccf:"CCF-B",type:"NLP",pdf:"https://doi.org/10.1137/1.9781611977653.ch101",code:"",page:"",slide:"",comment:"",tldr:"Zero-shot stance detection is challenging because it requires detecting the stance of previously unseen targets in the inference phase. The ability to learn transferable target-invariant features is critical for zero-shot stance detection. In this paper, we propose a stance detection approach that can efficiently adapt to unseen targets, the core of which is to capture target-invariant syntactic expression patterns as transferable knowledge. To be specific, we first augment the data by masking the topic words of sentences, and then feed the augmented data to an unsupervised contrastive learning module to capture transferable features. Besides, to fit a specific target, we encode the raw text as target-specific features. Finally, we adopt an attention mechanism, which combines syntactic expression patterns with target-specific features to obtain enhanced features for predicting previously unseen targets. Experiments demonstrate that our model outperforms baselines on four benchmark datasets."},{author:"<span style='font-weight:bold'}>Feng Xie</span>, Zhong Zhang, Liang Li, Bin Zhou and Yusong Tan.",title:"EpiGNN: Exploring Spatial Transmission with Graph Neural Network for Regional Epidemic Forecasting",venues:"The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases",abbr:"ECML-PKDD 2022",ccf:"CCF-B",type:"TSA",pdf:"https://link.springer.com/chapter/10.1007/978-3-031-26422-1_29",code:"https://github.com/Xiefeng69/EpiGNN",page:"/EpiGNN",slide:"/static/EpiGNN_presentation.pdf",comment:"",tldr:"Epidemic forecasting is the key to effective control of epidemic transmission and helps the world mitigate the crisis that threatens public health. To better understand the transmission and evolution of epidemics, we propose EpiGNN, a graph neural network-based model for epidemic forecasting. Specifically, we design a transmission risk encoding module to characterize local and global spatial effects of regions in epidemic processes and incorporate them into the model. Meanwhile, we develop a Region-Aware Graph Learner (RAGL) that takes transmission risk, geographical dependencies, and temporal information into account to better explore spatial-temporal dependencies and makes regions aware of related regions' epidemic situations. The RAGL can also combine with external resources, such as human mobility, to further improve prediction performance. Comprehensive experiments on five real-world epidemic-related datasets (including influenza and COVID-19) demonstrate the effectiveness of our proposed method and show that EpiGNN outperforms state-of-the-art baselines by 9.48% in RMSE."},{author:"<span style='font-weight:bold'}>Feng Xie</span>, Zhong Zhang, Xuechen Zhao, Bin Zhou and Yusong Tan.",title:"Inter- and Intra-Series Embeddings Fusion Network for Epidemiological Forecasting",venues:"The 34th International Conference on Software Engineering & Knowledge Engineering",abbr:"SEKE 2022",ccf:"CCF-C",type:"TSA",pdf:"http://dx.doi.org/10.18293/SEKE2022-109",code:"https://github.com/Xiefeng69/SEFNet",page:"/SEFNet",slide:"",comment:"",tldr:"The accurate forecasting of infectious epidemic diseases is the key to effective control of the epidemic situation in a region. Most existing methods ignore potential dynamic dependencies between regions or the importance of temporal dependencies and inter-dependencies between regions for prediction. In this paper, we propose an Inter- and Intra-Series Embeddings Fusion Network (SEFNet) to improve epidemic prediction performance. SEFNet consists of two parallel modules, named Inter-Series Embedding Module and Intra-Series Embedding Module. In Inter-Series Embedding Module, a multi-scale unified convolution component called Region-Aware Convolution is proposed, which cooperates with self-attention to capture dynamic dependencies between time series obtained from multiple regions. The Intra-Series Embedding Module uses Long Short-Term Memory to capture temporal relationships within each time series. Subsequently, we learn the influence degree of two embeddings and fuse them with the parametric-matrix fusion method. To further improve the robustness, SEFNet also integrates a traditional autoregressive component in parallel with nonlinear neural networks. Experiments on four real-world epidemic-related datasets show SEFNet is effective and outperforms state-of-the-art baselines."}];if("all"==e)return t;for(var n=[],a=0,i=t;a<i.length;a++){var o=i[a];o.type==e&&n.push(o)}return n}}}]);
//# sourceMappingURL=component---src-pages-publications-js-2d5c23aefdce9973078f.js.map